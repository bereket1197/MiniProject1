{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Written text as operational data\n",
    "\n",
    "Written text is one type of data\n",
    "\n",
    "### Why people write?\n",
    "\n",
    " - To communicate: their thoughts, feelings, urgency, needs, information\n",
    "\n",
    "### Why people communicate?\n",
    "\n",
    "1. To express emotions\n",
    "1. To share information\n",
    "1. To enable or elicit an action\n",
    "1. ...\n",
    "\n",
    "### We will use written text for the purpose other than \n",
    "1. To experience emotion\n",
    "1. To learn something the author intended us to learn\n",
    "1. To do what the author intended us to do\n",
    "\n",
    "### Instead, we will use written text to recognize who wrote it\n",
    " - By calculating and comparing word frequencies in written documents\n",
    " \n",
    "See, for example, likely fictional story https://medium.com/@amuse/how-the-nsa-caught-satoshi-nakamoto-868affcef595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1. Dictionaries in python (associative arrays)\n",
    "\n",
    "Plot the frequency distribution of words on a web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE\t1\n",
      "PUBLIC\t1\n",
      "\"-//IETF//DTD\t1\n",
      "2.0//EN\">\t1\n",
      "<html><head>\t1\n",
      "<title>403\t1\n",
      "Forbidden</title>\t1\n",
      "</head><body>\t1\n",
      "<h1>Forbidden</h1>\t1\n",
      "<p>You\t1\n",
      "don't\t1\n",
      "have\t1\n",
      "permission\t1\n",
      "to\t1\n"
     ]
    }
   ],
   "source": [
    "import requests, re\n",
    "# re is a module for regular expressions: to detect various combinations of characters\n",
    "import operator\n",
    "\n",
    "# Start from a simple document\n",
    "r = requests .get('http://eecs.utk.edu')\n",
    "\n",
    "# What comes back includes headers and other HTTP stuff, get just the body of the response\n",
    "t = r.text\n",
    "\n",
    "# obtain words by splitting a string using as separator one or more (+) space/like characters (\\s) \n",
    "wds = re.split('\\s+',t)\n",
    "\n",
    "# now populate a dictionary (wf)\n",
    "wf = {}\n",
    "for w in wds:\n",
    "    if w in wf: wf [w] = wf [w] + 1\n",
    "    else:  wf[w] = 1\n",
    "\n",
    "# dictionaries can not be sorted, so lets get a sorted *list*        \n",
    "wfs = sorted (wf .items(), key = operator .itemgetter (1), reverse=True)   \n",
    "\n",
    "# lets just have no more than 15 words \n",
    "ml = min(len(wfs),15)\n",
    "for i in range(1,ml,1):\n",
    "    print (wfs[i][0]+\"\\t\"+str(wfs[i][1]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Lots of markup in the output, lets remove it --- \n",
    "\n",
    "use BeautifulSoup and nltk modules and practice some regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\t2836\n",
      "of\t2676\n",
      "to\t2646\n",
      "a\t2217\n",
      "in\t1422\n",
      "his\t1205\n",
      "he\t928\n",
      "that\t920\n",
      "was\t823\n",
      "for\t798\n",
      "with\t797\n",
      "as\t672\n",
      "I\t505\n",
      "you\t497\n"
     ]
    }
   ],
   "source": [
    "#In case Project gutenberg is blocked you can download text to your laptop and copy to the docker container via scp\n",
    "#Assuming the file name you copy is pg4680.txt here is how you change the script\n",
    "# Please note the option errors='replace'\n",
    "# without it python invariably runs into unicode errors\n",
    "import requests, re, nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import clean_html\n",
    "from collections import Counter\n",
    "import operator\n",
    "f = open ('pg4680.txt', 'r', encoding=\"ascii\", errors='replace')\n",
    "    \n",
    "# What comes back includes headers and other HTTP stuff, get just the body of the response\n",
    "t = f.read()\n",
    "\n",
    "# obtain words by splitting a string using as separator one or more (+) space/like characters (\\s) \n",
    "wds = re.split('\\s+',t)\n",
    "\n",
    "# now populate a dictionary (wf)\n",
    "wf = {}\n",
    "for w in wds:\n",
    "    if w in wf: wf [w] = wf [w] + 1\n",
    "    else:  wf [w] = 1\n",
    "\n",
    "# dictionaries can not be sorted, so lets get a sorted *list*        \n",
    "wfs = sorted (wf .items(), key = operator .itemgetter (1), reverse=True)   \n",
    "\n",
    "# lets just have no more than 15 words \n",
    "ml = min(len(wfs),15)\n",
    "for i in range(1,ml,1):\n",
    "    print (wfs[i][0]+\"\\t\"+str(wfs[i][1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 most frequent words in Dracula \n",
      "van\t322\n",
      "come\t325\n",
      "time\t364\n",
      "know\t382\n",
      "see\t385\n",
      "may\t409\n",
      "shall\t426\n",
      "would\t428\n",
      "us\t447\n",
      "must\t448\n",
      "said\t461\n",
      "one\t489\n",
      "could\t490\n",
      "\t790\n",
      "\n",
      "15 most frequent words in Frankenstein\n",
      "eyes\t103\n",
      "shall\t107\n",
      "might\t108\n",
      "first\t108\n",
      "life\t109\n",
      "every\t109\n",
      "father\t111\n",
      "may\t113\n",
      "man\t125\n",
      "upon\t128\n",
      "yet\t152\n",
      "would\t183\n",
      "could\t197\n",
      "one\t203\n"
     ]
    }
   ],
   "source": [
    "#compare two books from different authors\n",
    "import requests, re, nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import clean_html\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "# we may not care about the usage of stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english') + [\n",
    " 'ut', '\\'re','.', ',', '--', '\\'s', '?', ')', '(', ':', '\\'',\n",
    " '\\\"', '-', '}', '{', '&', '|', u'\\u2014' ]\n",
    "\n",
    "# We most likely would like to remove html markup\n",
    "def cleanHtml (html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup .get_text()\n",
    "\n",
    "# We also want to remove special characters, quotes, etc. from each word\n",
    "def cleanWord (w):\n",
    "    # r in r'[.,\"\\']' tells to treat \\ as a regular character \n",
    "    # but we need to escape ' with \\'\n",
    "    # any character between the brackets [] is to be removed \n",
    "    wn = re.sub('[,\"\\.\\'&\\|:@>*;/=]', \"\", w)\n",
    "    # get rid of numbers\n",
    "    return re.sub('^[0-9\\.]*$', \"\", wn)\n",
    "       \n",
    "# define a function to get text/clean/calculate frequency\n",
    "def get_wf (URL):\n",
    "    # first get the web page\n",
    "    r = requests .get(URL)\n",
    "    \n",
    "    # Now clean\n",
    "    # remove html markup\n",
    "    t = cleanHtml (r .text) .lower()\n",
    "    \n",
    "    # split string into an array of words using any sequence of spaces \"\\s+\" \n",
    "    wds = re .split('\\s+',t)\n",
    "    \n",
    "    # remove periods, commas, etc stuck to the edges of words\n",
    "    for i in range(len(wds)):\n",
    "        wds [i] = cleanWord (wds [i])\n",
    "    \n",
    "    # If satisfied with results, lets go to the next step: calculate frequencies\n",
    "    # We can write a loop to create a dictionary, but \n",
    "    # there is a special function for everything in python\n",
    "    # in particular for counting frequencies (like function table() in R)\n",
    "    wf = Counter (wds)\n",
    "    \n",
    "    # Remove stop words from the dictionary wf\n",
    "    for k in stop_words:\n",
    "        wf. pop(k, None)\n",
    "        \n",
    "    #how many regular words in the document?\n",
    "    tw = 0\n",
    "    for w in wf:\n",
    "       tw += wf[w] \n",
    "        \n",
    "    \n",
    "    # Get ordered list\n",
    "    wfs = sorted (wf .items(), key = operator.itemgetter(1), reverse=True)\n",
    "    ml = min(len(wfs),15)\n",
    "\n",
    "    #Reverse the list because barh plots items from the bottom\n",
    "    return (wfs [ 0:ml ] [::-1], tw)\n",
    "        \n",
    "# Now populate two lists    \n",
    "(wf_ee, tw_ee) = get_wf('http://www.gutenberg.org/ebooks/345.txt.utf-8')\n",
    "(wf_bu, tw_bu) = get_wf('http://www.gutenberg.org/ebooks/84.txt.utf-8')\n",
    "\n",
    "print(\"15 most frequent words in Dracula \")\n",
    "ml = min(len(wf_ee),15)\n",
    "for i in range(1,ml,1):\n",
    "    print (wf_ee[i][0]+\"\\t\"+str(wf_ee[i][1]))\n",
    "    \n",
    "print(\"\\n15 most frequent words in Frankenstein\")\n",
    "ml = min(len(wf_bu),15)\n",
    "for i in range(1,ml,1):\n",
    "    print (wf_bu[i][0]+\"\\t\"+str(wf_bu[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "1. Compare word frequencies between two works of a single author.\n",
    "1. Compare word frequencies between works of two authors.\n",
    "1. Are there some words preferred by one author but used less frequently by another author?\n",
    "\n",
    "Extra credit\n",
    "\n",
    "1. The frequency of a specific word, e.g., \"would\" should follow a binomial distribution (each regular word in a document is a trial and with probability p that word is \"would\". The estimate for p is N(\"would\")/N(regular word)). Do these binomial distributions for your chosen word differ significantly between books of the same author or between authors? \n",
    "\n",
    "Project Gutenberg is a good source of for fiction and non-fiction.\n",
    "\n",
    "E.g below are two most popular books from Project Gutenberg:\n",
    "- Pride and Prejudice at http://www.gutenberg.org/ebooks/1342.txt.utf-8\n",
    "- Adventures of Huckleberry Finn at http://www.gutenberg.org/ebooks/76.txt.utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101  most frequent words in The Illiad and The Odyssey by Homer \n",
      "# 1\n",
      "fields\t125 uses in The Illiad\n",
      "place\t91 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 2\n",
      "next\t126 uses in The Illiad\n",
      "whether\t93 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 3\n",
      "whole\t126 uses in The Illiad\n",
      "“i\t94 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 4\n",
      "fury\t126 uses in The Illiad\n",
      "find\t95 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 5\n",
      "beneath\t128 uses in The Illiad\n",
      "return\t95 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 6\n",
      "along\t128 uses in The Illiad\n",
      "end\t96 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 7\n",
      "power\t129 uses in The Illiad\n",
      "however\t96 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 8\n",
      "full\t130 uses in The Illiad\n",
      "ithaca\t98 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 9\n",
      "host\t130 uses in The Illiad\n",
      "hand\t99 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 10\n",
      "last\t130 uses in The Illiad\n",
      "heard\t101 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 11\n",
      "even\t130 uses in The Illiad\n",
      "going\t102 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 12\n",
      "spear\t130 uses in The Illiad\n",
      "soon\t103 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 13\n",
      "heart\t132 uses in The Illiad\n",
      "gave\t104 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 14\n",
      "two\t135 uses in The Illiad\n",
      "well\t104 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 15\n",
      "arm\t136 uses in The Illiad\n",
      "work\t104 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 16\n",
      "steeds\t137 uses in The Illiad\n",
      "penelope\t106 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 17\n",
      "flies\t138 uses in The Illiad\n",
      "yet\t106 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 18\n",
      "swift\t138 uses in The Illiad\n",
      "country\t106 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 19\n",
      "us\t140 uses in The Illiad\n",
      "water\t110 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 20\n",
      "hero\t141 uses in The Illiad\n",
      "wine\t111 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 21\n",
      "fair\t143 uses in The Illiad\n",
      "brought\t112 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 22\n",
      "slain\t144 uses in The Illiad\n",
      "say\t112 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 23\n",
      "sacred\t144 uses in The Illiad\n",
      "another\t114 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 24\n",
      "care\t144 uses in The Illiad\n",
      "thus\t115 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 25\n",
      "stood\t144 uses in The Illiad\n",
      "every\t116 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 26\n",
      "see\t144 uses in The Illiad\n",
      "told\t117 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 27\n",
      "way\t144 uses in The Illiad\n",
      "might\t119 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 28\n",
      "foe\t145 uses in The Illiad\n",
      "without\t120 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 29\n",
      "dead\t145 uses in The Illiad\n",
      "first\t120 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 30\n",
      "shore\t146 uses in The Illiad\n",
      "time\t122 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 31\n",
      "skies\t147 uses in The Illiad\n",
      "left\t126 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 32\n",
      "spoke\t148 uses in The Illiad\n",
      "put\t126 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 33\n",
      "ajax\t150 uses in The Illiad\n",
      "therefore\t126 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 34\n",
      "fall\t151 uses in The Illiad\n",
      "saw\t128 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 35\n",
      "train\t151 uses in The Illiad\n",
      "never\t130 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 36\n",
      "brave\t152 uses in The Illiad\n",
      "must\t132 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 37\n",
      "soul\t152 uses in The Illiad\n",
      "day\t132 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 38\n",
      "far\t152 uses in The Illiad\n",
      "know\t136 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 39\n",
      "men\t153 uses in The Illiad\n",
      "many\t137 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 40\n",
      "till\t154 uses in The Illiad\n",
      "though\t138 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 41\n",
      "blood\t156 uses in The Illiad\n",
      "\t139 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 42\n",
      "homer\t157 uses in The Illiad\n",
      "give\t140 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 43\n",
      "race\t159 uses in The Illiad\n",
      "away\t141 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 44\n",
      "head\t159 uses in The Illiad\n",
      "even\t142 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 45\n",
      "fierce\t160 uses in The Illiad\n",
      "two\t142 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 46\n",
      "grecian\t163 uses in The Illiad\n",
      "hands\t143 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 47\n",
      "long\t164 uses in The Illiad\n",
      "round\t144 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 48\n",
      "must\t165 uses in The Illiad\n",
      "among\t145 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 49\n",
      "death\t166 uses in The Illiad\n",
      "minerva\t148 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 50\n",
      "still\t169 uses in The Illiad\n",
      "get\t148 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 51\n",
      "every\t171 uses in The Illiad\n",
      "heaven\t149 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 52\n",
      "around\t172 uses in The Illiad\n",
      "old\t149 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 53\n",
      "bold\t172 uses in The Illiad\n",
      "long\t150 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 54\n",
      "man\t174 uses in The Illiad\n",
      "answered\t154 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 55\n",
      "breast\t179 uses in The Illiad\n",
      "jove\t157 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 56\n",
      "ground\t180 uses in The Illiad\n",
      "till\t158 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 57\n",
      "said\t180 uses in The Illiad\n",
      "also\t160 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 58\n",
      "rage\t185 uses in The Illiad\n",
      "way\t163 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 59\n",
      "round\t185 uses in The Illiad\n",
      "like\t166 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 60\n",
      "king\t188 uses in The Illiad\n",
      "set\t167 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 61\n",
      "field\t199 uses in The Illiad\n",
      "still\t172 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 62\n",
      "greeks\t199 uses in The Illiad\n",
      "people\t175 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 63\n",
      "thee\t205 uses in The Illiad\n",
      "gods\t175 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 64\n",
      "vain\t207 uses in The Illiad\n",
      "got\t179 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 65\n",
      "force\t210 uses in The Illiad\n",
      "make\t181 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 66\n",
      "high\t215 uses in The Illiad\n",
      "great\t185 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 67\n",
      "fate\t216 uses in The Illiad\n",
      "father\t185 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 68\n",
      "greece\t220 uses in The Illiad\n",
      "[\t186 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 69\n",
      "eyes\t221 uses in The Illiad\n",
      "sea\t186 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 70\n",
      "heaven\t222 uses in The Illiad\n",
      "took\t191 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 71\n",
      "trojan\t223 uses in The Illiad\n",
      "let\t199 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 72\n",
      "like\t234 uses in The Illiad\n",
      "take\t199 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 73\n",
      "whose\t237 uses in The Illiad\n",
      "back\t199 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 74\n",
      "may\t237 uses in The Illiad\n",
      "good\t202 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 75\n",
      "day\t238 uses in The Illiad\n",
      "much\t204 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 76\n",
      "fight\t238 uses in The Illiad\n",
      "came\t211 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 77\n",
      "plain\t239 uses in The Illiad\n",
      "shall\t215 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 78\n",
      "hand\t246 uses in The Illiad\n",
      "ship\t217 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 79\n",
      "chief\t247 uses in The Illiad\n",
      "made\t218 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 80\n",
      "let\t270 uses in The Illiad\n",
      "could\t218 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 81\n",
      "son\t271 uses in The Illiad\n",
      "home\t222 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 82\n",
      "gods\t272 uses in The Illiad\n",
      "suitors\t235 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 83\n",
      "troy\t275 uses in The Illiad\n",
      "telemachus\t245 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 84\n",
      "god\t277 uses in The Illiad\n",
      "son\t256 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 85\n",
      "first\t284 uses in The Illiad\n",
      "see\t256 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 86\n",
      "jove\t306 uses in The Illiad\n",
      "tell\t261 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 87\n",
      "war\t310 uses in The Illiad\n",
      "may\t264 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 88\n",
      "yet\t311 uses in The Illiad\n",
      "go\t265 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 89\n",
      "\t311 uses in The Illiad\n",
      "upon\t270 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 90\n",
      "achilles\t313 uses in The Illiad\n",
      "come\t280 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 91\n",
      "thou\t336 uses in The Illiad\n",
      "went\t300 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 92\n",
      "one\t342 uses in The Illiad\n",
      "us\t300 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 93\n",
      "hector\t347 uses in The Illiad\n",
      "man\t310 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 94\n",
      "o’er\t363 uses in The Illiad\n",
      "men\t311 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 95\n",
      "arms\t426 uses in The Illiad\n",
      "would\t380 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 96\n",
      "great\t462 uses in The Illiad\n",
      "house\t382 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 97\n",
      "shall\t504 uses in The Illiad\n",
      "said\t482 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 98\n",
      "thus\t606 uses in The Illiad\n",
      "one\t549 uses in The Odyssey\n",
      "\n",
      "\n",
      "# 99\n",
      "thy\t931 uses in The Illiad\n",
      "ulysses\t581 uses in The Odyssey\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compare two books from different same author\n",
    "import requests, re, nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import clean_html\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "# we may not care about the usage of stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english') + [\n",
    " 'ut', '\\'re','.', ',', '--', '\\'s', '?', ')', '(', ':', '\\'',\n",
    " '\\\"', '-', '}', '{', '&', '|', u'\\u2014', '\\n' ]\n",
    "\n",
    "# We most likely would like to remove html markup\n",
    "def cleanHtml (html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup .get_text()\n",
    "\n",
    "# We also want to remove special characters, quotes, etc. from each word\n",
    "def cleanWord (w):\n",
    "    # r in r'[.,\"\\']' tells to treat \\ as a regular character \n",
    "    # but we need to escape ' with \\'\n",
    "    # any character between the brackets [] is to be removed \n",
    "    wn = re.sub('[,\"\\.\\'&\\|:@>*;/=]', \"\", w)\n",
    "    # get rid of numbers\n",
    "    return re.sub('^[0-9\\.]*$', \"\", wn)\n",
    "       \n",
    "# define a function to get text/clean/calculate frequency\n",
    "def get_wf (URL):\n",
    "    # first get the web page\n",
    "    r = requests .get(URL)\n",
    "    number_of_words = 100\n",
    "    # Now clean\n",
    "    # remove html markup\n",
    "    t = cleanHtml (r .text) .lower()\n",
    "    \n",
    "    # split string into an array of words using any sequence of spaces \"\\s+\" \n",
    "    wds = re .split('\\s+',t)\n",
    "    \n",
    "    # remove periods, commas, etc stuck to the edges of words\n",
    "    for i in range(len(wds)):\n",
    "        wds [i] = cleanWord (wds [i])\n",
    "    \n",
    "    # If satisfied with results, lets go to the next step: calculate frequencies\n",
    "    # We can write a loop to create a dictionary, but \n",
    "    # there is a special function for everything in python\n",
    "    # in particular for counting frequencies (like function table() in R)\n",
    "    wf = Counter (wds)\n",
    "    \n",
    "    # Remove stop words from the dictionary wf\n",
    "    for k in stop_words:\n",
    "        wf. pop(k, None)\n",
    "        \n",
    "    #how many regular words in the document?\n",
    "    tw = 0\n",
    "    for w in wf:\n",
    "       tw += wf[w] \n",
    "        \n",
    "    \n",
    "    # Get ordered list\n",
    "    wfs = sorted (wf .items(), key = operator.itemgetter(1), reverse=True)\n",
    "    ml = min(len(wfs),number_of_words)\n",
    "\n",
    "    #Reverse the list because barh plots items from the bottom\n",
    "    return (wfs [ 0:ml ] [::-1], tw)\n",
    "        \n",
    "# Now populate two lists    \n",
    "(wf_ee, tw_ee) = get_wf('http://www.gutenberg.org/ebooks/6130.txt.utf-8')\n",
    "(wf_bu, tw_bu) = get_wf('http://www.gutenberg.org/ebooks/1727.txt.utf-8')\n",
    "\n",
    "num = 100\n",
    "\n",
    "print(number_of_words,\" most frequent words in The Illiad and The Odyssey by Homer \")\n",
    "\n",
    "\n",
    "ml = min(len(wf_ee),num)\n",
    "rank = 1\n",
    "for i in range(1,ml,1):\n",
    "    print (\"#\",rank,)\n",
    "    print (wf_ee[i][0]+\"\\t\"+str(wf_ee[i][1]), \"uses in The Illiad\")\n",
    "    print (wf_bu[i][0]+\"\\t\"+str(wf_bu[i][1]), \"uses in The Odyssey\")\n",
    "    print('\\n')\n",
    "    rank+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 most frequent words in Dracula and Frankenstein \n",
      "# 1\n",
      "van\t322 uses in Dracula\n",
      "eyes\t103 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 2\n",
      "come\t325 uses in Dracula\n",
      "shall\t107 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 3\n",
      "time\t364 uses in Dracula\n",
      "might\t108 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 4\n",
      "know\t382 uses in Dracula\n",
      "first\t108 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 5\n",
      "see\t385 uses in Dracula\n",
      "life\t109 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 6\n",
      "may\t409 uses in Dracula\n",
      "every\t109 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 7\n",
      "shall\t426 uses in Dracula\n",
      "father\t111 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 8\n",
      "would\t428 uses in Dracula\n",
      "may\t113 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 9\n",
      "us\t447 uses in Dracula\n",
      "man\t125 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 10\n",
      "must\t448 uses in Dracula\n",
      "upon\t128 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 11\n",
      "said\t461 uses in Dracula\n",
      "yet\t152 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 12\n",
      "one\t489 uses in Dracula\n",
      "would\t183 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 13\n",
      "could\t490 uses in Dracula\n",
      "could\t197 uses in Frankenstein\n",
      "\n",
      "\n",
      "# 14\n",
      "\t790 uses in Dracula\n",
      "one\t203 uses in Frankenstein\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compare two books from different authors\n",
    "import requests, re, nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import clean_html\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "# we may not care about the usage of stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english') + [\n",
    " 'ut', '\\'re','.', ',', '--', '\\'s', '?', ')', '(', ':', '\\'',\n",
    " '\\\"', '-', '}', '{', '&', '|', u'\\u2014' ]\n",
    "\n",
    "# We most likely would like to remove html markup\n",
    "def cleanHtml (html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup .get_text()\n",
    "\n",
    "# We also want to remove special characters, quotes, etc. from each word\n",
    "def cleanWord (w):\n",
    "    # r in r'[.,\"\\']' tells to treat \\ as a regular character \n",
    "    # but we need to escape ' with \\'\n",
    "    # any character between the brackets [] is to be removed \n",
    "    wn = re.sub('[,\"\\.\\'&\\|:@>*;/=]', \"\", w)\n",
    "    # get rid of numbers\n",
    "    return re.sub('^[0-9\\.]*$', \"\", wn)\n",
    "       \n",
    "# define a function to get text/clean/calculate frequency\n",
    "def get_wf (URL):\n",
    "    # first get the web page\n",
    "    r = requests .get(URL)\n",
    "    \n",
    "    # Now clean\n",
    "    # remove html markup\n",
    "    t = cleanHtml (r .text) .lower()\n",
    "    \n",
    "    # split string into an array of words using any sequence of spaces \"\\s+\" \n",
    "    wds = re .split('\\s+',t)\n",
    "    \n",
    "    # remove periods, commas, etc stuck to the edges of words\n",
    "    for i in range(len(wds)):\n",
    "        wds [i] = cleanWord (wds [i])\n",
    "    \n",
    "    # If satisfied with results, lets go to the next step: calculate frequencies\n",
    "    # We can write a loop to create a dictionary, but \n",
    "    # there is a special function for everything in python\n",
    "    # in particular for counting frequencies (like function table() in R)\n",
    "    wf = Counter (wds)\n",
    "    \n",
    "    # Remove stop words from the dictionary wf\n",
    "    for k in stop_words:\n",
    "        wf. pop(k, None)\n",
    "        \n",
    "    #how many regular words in the document?\n",
    "    tw = 0\n",
    "    for w in wf:\n",
    "       tw += wf[w] \n",
    "        \n",
    "    \n",
    "    # Get ordered list\n",
    "    wfs = sorted (wf .items(), key = operator.itemgetter(1), reverse=True)\n",
    "    ml = min(len(wfs),15)\n",
    "\n",
    "    #Reverse the list because barh plots items from the bottom\n",
    "    return (wfs [ 0:ml ] [::-1], tw)\n",
    "        \n",
    "# Now populate two lists    \n",
    "(wf_ee, tw_ee) = get_wf('http://www.gutenberg.org/ebooks/345.txt.utf-8')\n",
    "(wf_bu, tw_bu) = get_wf('http://www.gutenberg.org/ebooks/84.txt.utf-8')\n",
    "\n",
    "print(\"15 most frequent words in Dracula and Frankenstein \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
